{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUANWN3rpfC9"
      },
      "source": [
        "# 0. Setup Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "146BB11JpfDA"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "42hJEdo_pfDB"
      },
      "outputs": [],
      "source": [
        "CUSTOM_MODEL_NAME = 'my_ssd_mobnet' \n",
        "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
        "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
        "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
        "LABEL_MAP_NAME = 'label_map.pbtxt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hbPhYVy_pfDB"
      },
      "outputs": [],
      "source": [
        "paths = {\n",
        "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
        "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
        "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
        "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
        "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
        "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
        "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
        "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
        "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
        "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
        "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
        "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
        " }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LwhWZMI0pfDC"
      },
      "outputs": [],
      "source": [
        "files = {\n",
        "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
        "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
        "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HR-TfDGrpfDC"
      },
      "outputs": [],
      "source": [
        "for path in paths.values():\n",
        "    if not os.path.exists(path):\n",
        "        if os.name == 'posix':\n",
        "            !mkdir -p {path}\n",
        "        if os.name == 'nt':\n",
        "            !mkdir {path}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLU-rs_ipfDE"
      },
      "source": [
        "# 1. Download TF Models Pretrained Models from Tensorflow Model Zoo and Install TFOD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "k6hdumV0BEPD"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "K-Cmz2edpfDE",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "if os.name=='nt':\n",
        "    !pip install wget\n",
        "    import wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iA1DIq5OpfDE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ae12c83-e42b-46b7-e5db-d19cf19d4a9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Tensorflow/models'...\n",
            "remote: Enumerating objects: 72697, done.\u001b[K\n",
            "remote: Counting objects: 100% (206/206), done.\u001b[K\n",
            "remote: Compressing objects: 100% (140/140), done.\u001b[K\n",
            "remote: Total 72697 (delta 83), reused 182 (delta 63), pack-reused 72491\u001b[K\n",
            "Receiving objects: 100% (72697/72697), 579.29 MiB | 35.61 MiB/s, done.\n",
            "Resolving deltas: 100% (51374/51374), done.\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
        "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rJjMHbnDs3Tv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deab7bdb-3590-4273-aaba-6ff60d3a3a8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  libnvidia-common-460 nsight-compute-2020.2.0\n",
            "Use 'apt autoremove' to remove them.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 42 not upgraded.\n",
            "Processing /content/Tensorflow/models/research\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.38.0-cp37-cp37m-manylinux2010_x86_64.whl (10.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.2 MB 13.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.28)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 71.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.4)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.3.5)\n",
            "Collecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.8.0-py2.py3-none-any.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 47.2 MB/s \n",
            "\u001b[?25hCollecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.25.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.4 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.8.0)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.8 MB/s \n",
            "\u001b[?25hCollecting tensorflow-text~=2.8.0\n",
            "  Downloading tensorflow_text-2.8.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 51.2 MB/s \n",
            "\u001b[?25hCollecting py-cpuinfo>=3.3.0\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 11.3 MB/s \n",
            "\u001b[?25hCollecting pyyaml<6.0,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 61.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.11)\n",
            "Collecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.8 MB 49 kB/s \n",
            "\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 54.3 MB/s \n",
            "\u001b[?25hCollecting sacrebleu\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 13.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Requirement already satisfied: tensorflow~=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.21.6)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 44.6 MB/s \n",
            "\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.2-py2.py3-none-any.whl (237 kB)\n",
            "\u001b[K     |████████████████████████████████| 237 kB 76.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.31.5)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2022.1)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.56.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.10.8)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.8)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (4.2.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 2.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.25.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.44.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.5.3)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.8.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (14.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.6)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.8.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.7)\n",
            "Requirement already satisfied: pyarrow<7.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (6.0.1)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
            "Collecting requests<3.0.0dev,>=2.18.0\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 64.3 MB/s \n",
            "\u001b[?25hCollecting fastavro<2,>=0.23.6\n",
            "  Downloading fastavro-1.4.11-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 53.1 MB/s \n",
            "\u001b[?25hCollecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n",
            "\u001b[K     |████████████████████████████████| 508 kB 66.7 MB/s \n",
            "\u001b[?25hCollecting cloudpickle<3,>=2.0.0\n",
            "  Downloading cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Collecting orjson<4.0\n",
            "  Downloading orjson-3.6.8-cp37-cp37m-manylinux_2_24_x86_64.whl (253 kB)\n",
            "\u001b[K     |████████████████████████████████| 253 kB 76.8 MB/s \n",
            "\u001b[?25hCollecting proto-plus<2,>=1.7.1\n",
            "  Downloading proto_plus-1.20.3-py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Collecting protobuf>=3.12.0\n",
            "  Downloading protobuf-3.20.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 48.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.12)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.4.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2019.12.20)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.16.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.4.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.7.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.7.0)\n",
            "Building wheels for collected packages: object-detection, py-cpuinfo, dill, avro-python3, seqeval\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1692480 sha256=bdb64665dbeaeec077a8ad6382cd2b9fef311ffaccb642007c980339911eab7d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4hv66uss/wheels/a9/26/bf/1cb2313ed4855917889b97658bf0a19999e3588e47867bdaee\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=00fdb89875e5711cd65079c7f66e54c327cb5840fcb4e29b393fd9a290c343bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=525371b46e59fb147865bd177b18afb687a4e6005c524960e103c3f3214ea6a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=5ed6b237ab18c36b08ea5b24cc062bf0a6e02746ad3e5cbb9c194eb5639d1ecc\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=0ba19cfe1e9badcf2d8d0c071fb19f7bd96f00003c11185ebca99fd56a00dea7\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built object-detection py-cpuinfo dill avro-python3 seqeval\n",
            "Installing collected packages: requests, protobuf, tf-estimator-nightly, portalocker, dill, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, py-cpuinfo, proto-plus, orjson, opencv-python-headless, hdfs, fastavro, cloudpickle, tf-models-official, tensorflow-io, lvis, avro-python3, apache-beam, object-detection\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.4\n",
            "    Uninstalling dill-0.3.4:\n",
            "      Successfully uninstalled dill-0.3.4\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 4.1.1\n",
            "    Uninstalling pymongo-4.1.1:\n",
            "      Successfully uninstalled pymongo-4.1.1\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed apache-beam-2.38.0 avro-python3-1.10.2 cloudpickle-2.0.0 colorama-0.4.4 dill-0.3.1.1 fastavro-1.4.11 hdfs-2.7.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.5.64 orjson-3.6.8 portalocker-2.4.0 proto-plus-1.20.3 protobuf-3.20.1 py-cpuinfo-8.0.0 pymongo-3.12.3 pyyaml-5.4.1 requests-2.27.1 sacrebleu-2.0.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.16.1 tensorflow-io-0.25.0 tensorflow-model-optimization-0.7.2 tensorflow-text-2.8.2 tf-estimator-nightly-2.8.0.dev2021122109 tf-models-official-2.8.0 tf-slim-1.1.0\n"
          ]
        }
      ],
      "source": [
        "# Install Tensorflow Object Detection \n",
        "if os.name=='posix':  \n",
        "    !apt-get install protobuf-compiler\n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
        "    \n",
        "if os.name=='nt':\n",
        "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
        "    wget.download(url)\n",
        "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
        "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
        "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
        "    !cd Tensorflow/models/research/slim && pip install -e . "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtlQSLz6BEPG",
        "outputId": "0e8b868e-a161-46cb-ac51-d25c55e82b54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                       Version\n",
            "----------------------------- ---------------------\n",
            "absl-py                       1.0.0\n",
            "alabaster                     0.7.12\n",
            "albumentations                0.1.12\n",
            "altair                        4.2.0\n",
            "apache-beam                   2.38.0\n",
            "appdirs                       1.4.4\n",
            "argon2-cffi                   21.3.0\n",
            "argon2-cffi-bindings          21.2.0\n",
            "arviz                         0.12.0\n",
            "astor                         0.8.1\n",
            "astropy                       4.3.1\n",
            "astunparse                    1.6.3\n",
            "atari-py                      0.2.9\n",
            "atomicwrites                  1.4.0\n",
            "attrs                         21.4.0\n",
            "audioread                     2.1.9\n",
            "autograd                      1.4\n",
            "avro-python3                  1.10.2\n",
            "Babel                         2.10.1\n",
            "backcall                      0.2.0\n",
            "beautifulsoup4                4.6.3\n",
            "bleach                        5.0.0\n",
            "blis                          0.4.1\n",
            "bokeh                         2.3.3\n",
            "Bottleneck                    1.3.4\n",
            "branca                        0.5.0\n",
            "bs4                           0.0.1\n",
            "CacheControl                  0.12.11\n",
            "cached-property               1.5.2\n",
            "cachetools                    4.2.4\n",
            "catalogue                     1.0.0\n",
            "certifi                       2021.10.8\n",
            "cffi                          1.15.0\n",
            "cftime                        1.6.0\n",
            "chardet                       3.0.4\n",
            "charset-normalizer            2.0.12\n",
            "click                         7.1.2\n",
            "cloudpickle                   2.0.0\n",
            "cmake                         3.22.4\n",
            "cmdstanpy                     0.9.5\n",
            "colorama                      0.4.4\n",
            "colorcet                      3.0.0\n",
            "colorlover                    0.3.0\n",
            "community                     1.0.0b1\n",
            "contextlib2                   0.5.5\n",
            "convertdate                   2.4.0\n",
            "coverage                      3.7.1\n",
            "coveralls                     0.5\n",
            "crcmod                        1.7\n",
            "cufflinks                     0.17.3\n",
            "cupy-cuda111                  9.4.0\n",
            "cvxopt                        1.2.7\n",
            "cvxpy                         1.0.31\n",
            "cycler                        0.11.0\n",
            "cymem                         2.0.6\n",
            "Cython                        0.29.28\n",
            "daft                          0.0.4\n",
            "dask                          2.12.0\n",
            "datascience                   0.10.6\n",
            "debugpy                       1.0.0\n",
            "decorator                     4.4.2\n",
            "defusedxml                    0.7.1\n",
            "descartes                     1.1.0\n",
            "dill                          0.3.1.1\n",
            "distributed                   1.25.3\n",
            "dlib                          19.18.0\n",
            "dm-tree                       0.1.7\n",
            "docopt                        0.6.2\n",
            "docutils                      0.17.1\n",
            "dopamine-rl                   1.0.5\n",
            "earthengine-api               0.1.307\n",
            "easydict                      1.9\n",
            "ecos                          2.0.10\n",
            "editdistance                  0.5.3\n",
            "en-core-web-sm                2.2.5\n",
            "entrypoints                   0.4\n",
            "ephem                         4.1.3\n",
            "et-xmlfile                    1.1.0\n",
            "fa2                           0.3.5\n",
            "fastai                        1.0.61\n",
            "fastavro                      1.4.11\n",
            "fastdtw                       0.3.4\n",
            "fastjsonschema                2.15.3\n",
            "fastprogress                  1.0.2\n",
            "fastrlock                     0.8\n",
            "fbprophet                     0.7.1\n",
            "feather-format                0.4.1\n",
            "filelock                      3.6.0\n",
            "firebase-admin                4.4.0\n",
            "fix-yahoo-finance             0.0.22\n",
            "Flask                         1.1.4\n",
            "flatbuffers                   2.0\n",
            "folium                        0.8.3\n",
            "future                        0.16.0\n",
            "gast                          0.5.3\n",
            "GDAL                          2.2.2\n",
            "gdown                         4.4.0\n",
            "gensim                        3.6.0\n",
            "geographiclib                 1.52\n",
            "geopy                         1.17.0\n",
            "gin-config                    0.5.0\n",
            "glob2                         0.7\n",
            "google                        2.0.3\n",
            "google-api-core               1.31.5\n",
            "google-api-python-client      1.12.11\n",
            "google-auth                   1.35.0\n",
            "google-auth-httplib2          0.0.4\n",
            "google-auth-oauthlib          0.4.6\n",
            "google-cloud-bigquery         1.21.0\n",
            "google-cloud-bigquery-storage 1.1.1\n",
            "google-cloud-core             1.0.3\n",
            "google-cloud-datastore        1.8.0\n",
            "google-cloud-firestore        1.7.0\n",
            "google-cloud-language         1.2.0\n",
            "google-cloud-storage          1.18.1\n",
            "google-cloud-translate        1.5.0\n",
            "google-colab                  1.0.0\n",
            "google-pasta                  0.2.0\n",
            "google-resumable-media        0.4.1\n",
            "googleapis-common-protos      1.56.0\n",
            "googledrivedownloader         0.4\n",
            "graphviz                      0.10.1\n",
            "greenlet                      1.1.2\n",
            "grpcio                        1.44.0\n",
            "gspread                       3.4.2\n",
            "gspread-dataframe             3.0.8\n",
            "gym                           0.17.3\n",
            "h5py                          3.1.0\n",
            "hdfs                          2.7.0\n",
            "HeapDict                      1.0.1\n",
            "hijri-converter               2.2.3\n",
            "holidays                      0.10.5.2\n",
            "holoviews                     1.14.8\n",
            "html5lib                      1.0.1\n",
            "httpimport                    0.5.18\n",
            "httplib2                      0.17.4\n",
            "httplib2shim                  0.0.3\n",
            "humanize                      0.5.1\n",
            "hyperopt                      0.1.2\n",
            "ideep4py                      2.0.0.post3\n",
            "idna                          2.10\n",
            "imageio                       2.4.1\n",
            "imagesize                     1.3.0\n",
            "imbalanced-learn              0.8.1\n",
            "imblearn                      0.0\n",
            "imgaug                        0.2.9\n",
            "importlib-metadata            4.11.3\n",
            "importlib-resources           5.7.1\n",
            "imutils                       0.5.4\n",
            "inflect                       2.1.0\n",
            "iniconfig                     1.1.1\n",
            "intel-openmp                  2022.1.0\n",
            "intervaltree                  2.1.0\n",
            "ipykernel                     4.10.1\n",
            "ipython                       5.5.0\n",
            "ipython-genutils              0.2.0\n",
            "ipython-sql                   0.3.9\n",
            "ipywidgets                    7.7.0\n",
            "itsdangerous                  1.1.0\n",
            "jax                           0.3.8\n",
            "jaxlib                        0.3.7+cuda11.cudnn805\n",
            "jedi                          0.18.1\n",
            "jieba                         0.42.1\n",
            "Jinja2                        2.11.3\n",
            "joblib                        1.1.0\n",
            "jpeg4py                       0.1.4\n",
            "jsonschema                    4.3.3\n",
            "jupyter                       1.0.0\n",
            "jupyter-client                5.3.5\n",
            "jupyter-console               5.2.0\n",
            "jupyter-core                  4.10.0\n",
            "jupyterlab-pygments           0.2.2\n",
            "jupyterlab-widgets            1.1.0\n",
            "kaggle                        1.5.12\n",
            "kapre                         0.3.7\n",
            "keras                         2.8.0\n",
            "Keras-Preprocessing           1.1.2\n",
            "keras-vis                     0.4.1\n",
            "kiwisolver                    1.4.2\n",
            "korean-lunar-calendar         0.2.1\n",
            "libclang                      14.0.1\n",
            "librosa                       0.8.1\n",
            "lightgbm                      2.2.3\n",
            "llvmlite                      0.34.0\n",
            "lmdb                          0.99\n",
            "LunarCalendar                 0.0.9\n",
            "lvis                          0.5.3\n",
            "lxml                          4.2.6\n",
            "Markdown                      3.3.6\n",
            "MarkupSafe                    2.0.1\n",
            "matplotlib                    3.2.2\n",
            "matplotlib-inline             0.1.3\n",
            "matplotlib-venn               0.11.7\n",
            "missingno                     0.5.1\n",
            "mistune                       0.8.4\n",
            "mizani                        0.6.0\n",
            "mkl                           2019.0\n",
            "mlxtend                       0.14.0\n",
            "more-itertools                8.12.0\n",
            "moviepy                       0.2.3.5\n",
            "mpmath                        1.2.1\n",
            "msgpack                       1.0.3\n",
            "multiprocess                  0.70.12.2\n",
            "multitasking                  0.0.10\n",
            "murmurhash                    1.0.7\n",
            "music21                       5.5.0\n",
            "natsort                       5.5.0\n",
            "nbclient                      0.6.2\n",
            "nbconvert                     5.6.1\n",
            "nbformat                      5.3.0\n",
            "nest-asyncio                  1.5.5\n",
            "netCDF4                       1.5.8\n",
            "networkx                      2.6.3\n",
            "nibabel                       3.0.2\n",
            "nltk                          3.2.5\n",
            "notebook                      5.3.1\n",
            "numba                         0.51.2\n",
            "numexpr                       2.8.1\n",
            "numpy                         1.21.6\n",
            "nvidia-ml-py3                 7.352.0\n",
            "oauth2client                  4.1.3\n",
            "oauthlib                      3.2.0\n",
            "object-detection              0.1\n",
            "okgrade                       0.4.3\n",
            "opencv-contrib-python         4.1.2.30\n",
            "opencv-python                 4.1.2.30\n",
            "opencv-python-headless        4.5.5.64\n",
            "openpyxl                      3.0.9\n",
            "opt-einsum                    3.3.0\n",
            "orjson                        3.6.8\n",
            "osqp                          0.6.2.post0\n",
            "packaging                     21.3\n",
            "palettable                    3.3.0\n",
            "pandas                        1.3.5\n",
            "pandas-datareader             0.9.0\n",
            "pandas-gbq                    0.13.3\n",
            "pandas-profiling              1.4.1\n",
            "pandocfilters                 1.5.0\n",
            "panel                         0.12.1\n",
            "param                         1.12.1\n",
            "parso                         0.8.3\n",
            "pathlib                       1.0.1\n",
            "patsy                         0.5.2\n",
            "pep517                        0.12.0\n",
            "pexpect                       4.8.0\n",
            "pickleshare                   0.7.5\n",
            "Pillow                        7.1.2\n",
            "pip                           21.1.3\n",
            "pip-tools                     6.2.0\n",
            "plac                          1.1.3\n",
            "plotly                        5.5.0\n",
            "plotnine                      0.6.0\n",
            "pluggy                        0.7.1\n",
            "pooch                         1.6.0\n",
            "portalocker                   2.4.0\n",
            "portpicker                    1.3.9\n",
            "prefetch-generator            1.0.1\n",
            "preshed                       3.0.6\n",
            "prettytable                   3.2.0\n",
            "progressbar2                  3.38.0\n",
            "prometheus-client             0.14.1\n",
            "promise                       2.3\n",
            "prompt-toolkit                1.0.18\n",
            "proto-plus                    1.20.3\n",
            "protobuf                      3.20.1\n",
            "psutil                        5.4.8\n",
            "psycopg2                      2.7.6.1\n",
            "ptyprocess                    0.7.0\n",
            "py                            1.11.0\n",
            "py-cpuinfo                    8.0.0\n",
            "pyarrow                       6.0.1\n",
            "pyasn1                        0.4.8\n",
            "pyasn1-modules                0.2.8\n",
            "pycocotools                   2.0.4\n",
            "pycparser                     2.21\n",
            "pyct                          0.4.8\n",
            "pydata-google-auth            1.4.0\n",
            "pydot                         1.3.0\n",
            "pydot-ng                      2.0.0\n",
            "pydotplus                     2.0.2\n",
            "PyDrive                       1.3.1\n",
            "pyemd                         0.5.1\n",
            "pyerfa                        2.0.0.1\n",
            "pyglet                        1.5.0\n",
            "Pygments                      2.6.1\n",
            "pygobject                     3.26.1\n",
            "pymc3                         3.11.4\n",
            "PyMeeus                       0.5.11\n",
            "pymongo                       3.12.3\n",
            "pymystem3                     0.2.0\n",
            "PyOpenGL                      3.1.6\n",
            "pyparsing                     3.0.8\n",
            "pyrsistent                    0.18.1\n",
            "pysndfile                     1.3.8\n",
            "PySocks                       1.7.1\n",
            "pystan                        2.19.1.1\n",
            "pytest                        3.6.4\n",
            "python-apt                    0.0.0\n",
            "python-chess                  0.23.11\n",
            "python-dateutil               2.8.2\n",
            "python-louvain                0.16\n",
            "python-slugify                6.1.2\n",
            "python-utils                  3.1.0\n",
            "pytz                          2022.1\n",
            "pyviz-comms                   2.2.0\n",
            "PyWavelets                    1.3.0\n",
            "PyYAML                        5.4.1\n",
            "pyzmq                         22.3.0\n",
            "qdldl                         0.1.5.post2\n",
            "qtconsole                     5.3.0\n",
            "QtPy                          2.1.0\n",
            "regex                         2019.12.20\n",
            "requests                      2.27.1\n",
            "requests-oauthlib             1.3.1\n",
            "resampy                       0.2.2\n",
            "rpy2                          3.4.5\n",
            "rsa                           4.8\n",
            "sacrebleu                     2.0.0\n",
            "scikit-image                  0.18.3\n",
            "scikit-learn                  1.0.2\n",
            "scipy                         1.4.1\n",
            "screen-resolution-extra       0.0.0\n",
            "scs                           3.2.0\n",
            "seaborn                       0.11.2\n",
            "semver                        2.13.0\n",
            "Send2Trash                    1.8.0\n",
            "sentencepiece                 0.1.96\n",
            "seqeval                       1.2.2\n",
            "setuptools                    57.4.0\n",
            "setuptools-git                1.2\n",
            "Shapely                       1.8.1.post1\n",
            "simplegeneric                 0.8.1\n",
            "six                           1.15.0\n",
            "sklearn                       0.0\n",
            "sklearn-pandas                1.8.0\n",
            "smart-open                    6.0.0\n",
            "snowballstemmer               2.2.0\n",
            "sortedcontainers              2.4.0\n",
            "SoundFile                     0.10.3.post1\n",
            "soupsieve                     2.3.2.post1\n",
            "spacy                         2.2.4\n",
            "Sphinx                        1.8.6\n",
            "sphinxcontrib-serializinghtml 1.1.5\n",
            "sphinxcontrib-websupport      1.2.4\n",
            "SQLAlchemy                    1.4.36\n",
            "sqlparse                      0.4.2\n",
            "srsly                         1.0.5\n",
            "statsmodels                   0.10.2\n",
            "sympy                         1.7.1\n",
            "tables                        3.7.0\n",
            "tabulate                      0.8.9\n",
            "tblib                         1.7.0\n",
            "tenacity                      8.0.1\n",
            "tensorboard                   2.8.0\n",
            "tensorboard-data-server       0.6.1\n",
            "tensorboard-plugin-wit        1.8.1\n",
            "tensorflow                    2.8.0\n",
            "tensorflow-addons             0.16.1\n",
            "tensorflow-datasets           4.0.1\n",
            "tensorflow-estimator          2.8.0\n",
            "tensorflow-gcs-config         2.8.0\n",
            "tensorflow-hub                0.12.0\n",
            "tensorflow-io                 0.25.0\n",
            "tensorflow-io-gcs-filesystem  0.25.0\n",
            "tensorflow-metadata           1.7.0\n",
            "tensorflow-model-optimization 0.7.2\n",
            "tensorflow-probability        0.16.0\n",
            "tensorflow-text               2.8.2\n",
            "termcolor                     1.1.0\n",
            "terminado                     0.13.3\n",
            "testpath                      0.6.0\n",
            "text-unidecode                1.3\n",
            "textblob                      0.15.3\n",
            "tf-estimator-nightly          2.8.0.dev2021122109\n",
            "tf-models-official            2.8.0\n",
            "tf-slim                       1.1.0\n",
            "Theano-PyMC                   1.1.2\n",
            "thinc                         7.4.0\n",
            "threadpoolctl                 3.1.0\n",
            "tifffile                      2021.11.2\n",
            "tinycss2                      1.1.1\n",
            "tomli                         2.0.1\n",
            "toolz                         0.11.2\n",
            "torch                         1.11.0+cu113\n",
            "torchaudio                    0.11.0+cu113\n",
            "torchsummary                  1.5.1\n",
            "torchtext                     0.12.0\n",
            "torchvision                   0.12.0+cu113\n",
            "tornado                       5.1.1\n",
            "tqdm                          4.64.0\n",
            "traitlets                     5.1.1\n",
            "tweepy                        3.10.0\n",
            "typeguard                     2.7.1\n",
            "typing-extensions             4.2.0\n",
            "tzlocal                       1.5.1\n",
            "uritemplate                   3.0.1\n",
            "urllib3                       1.24.3\n",
            "vega-datasets                 0.9.0\n",
            "wasabi                        0.9.1\n",
            "wcwidth                       0.2.5\n",
            "webencodings                  0.5.1\n",
            "Werkzeug                      1.0.1\n",
            "wheel                         0.37.1\n",
            "widgetsnbextension            3.6.0\n",
            "wordcloud                     1.5.0\n",
            "wrapt                         1.14.0\n",
            "xarray                        0.18.2\n",
            "xgboost                       0.90\n",
            "xkit                          0.0.0\n",
            "xlrd                          1.1.0\n",
            "xlwt                          1.3.0\n",
            "yellowbrick                   1.4\n",
            "zict                          2.2.0\n",
            "zipp                          3.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPBzmNYgBEPG",
        "outputId": "fadafa63-367c-498d-e360-b3b8687c4d39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running tests under Python 3.7.13: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2022-05-08 18:55:39.885697: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "W0508 18:55:40.315573 139796442945408 model_builder.py:1102] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 3.73s\n",
            "I0508 18:55:40.961114 139796442945408 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 3.73s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 1.08s\n",
            "I0508 18:55:42.038232 139796442945408 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 1.08s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.52s\n",
            "I0508 18:55:42.563110 139796442945408 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.52s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.52s\n",
            "I0508 18:55:43.080332 139796442945408 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.52s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 4.04s\n",
            "I0508 18:55:47.125133 139796442945408 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 4.04s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0508 18:55:47.126486 139796442945408 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.04s\n",
            "I0508 18:55:47.164082 139796442945408 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.04s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.03s\n",
            "I0508 18:55:47.193870 139796442945408 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.05s\n",
            "I0508 18:55:47.242040 139796442945408 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.05s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.23s\n",
            "I0508 18:55:47.487314 139796442945408 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.23s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.3s\n",
            "I0508 18:55:47.788939 139796442945408 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.3s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.24s\n",
            "I0508 18:55:48.027666 139796442945408 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.24s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.16s\n",
            "I0508 18:55:48.192942 139796442945408 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.16s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.17s\n",
            "I0508 18:55:48.365182 139796442945408 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.17s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.07s\n",
            "I0508 18:55:48.438726 139796442945408 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.07s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0508 18:55:48.736935 139796442945408 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0508 18:55:48.737186 139796442945408 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n",
            "I0508 18:55:48.737312 139796442945408 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n",
            "I0508 18:55:48.741587 139796442945408 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I0508 18:55:48.801876 139796442945408 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I0508 18:55:48.802112 139796442945408 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I0508 18:55:48.910575 139796442945408 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I0508 18:55:48.910825 139796442945408 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I0508 18:55:49.184764 139796442945408 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I0508 18:55:49.184988 139796442945408 efficientnet_model.py:144] round_filter input=40 output=40\n",
            "I0508 18:55:49.408684 139796442945408 efficientnet_model.py:144] round_filter input=40 output=40\n",
            "I0508 18:55:49.408905 139796442945408 efficientnet_model.py:144] round_filter input=80 output=80\n",
            "I0508 18:55:49.869667 139796442945408 efficientnet_model.py:144] round_filter input=80 output=80\n",
            "I0508 18:55:49.869922 139796442945408 efficientnet_model.py:144] round_filter input=112 output=112\n",
            "I0508 18:55:50.247701 139796442945408 efficientnet_model.py:144] round_filter input=112 output=112\n",
            "I0508 18:55:50.247915 139796442945408 efficientnet_model.py:144] round_filter input=192 output=192\n",
            "I0508 18:55:51.221419 139796442945408 efficientnet_model.py:144] round_filter input=192 output=192\n",
            "I0508 18:55:51.221648 139796442945408 efficientnet_model.py:144] round_filter input=320 output=320\n",
            "I0508 18:55:51.325669 139796442945408 efficientnet_model.py:144] round_filter input=1280 output=1280\n",
            "I0508 18:55:51.385846 139796442945408 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0508 18:55:51.531820 139796442945408 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0508 18:55:51.532043 139796442945408 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n",
            "I0508 18:55:51.532122 139796442945408 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 4\n",
            "I0508 18:55:51.535084 139796442945408 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I0508 18:55:51.552135 139796442945408 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I0508 18:55:51.552298 139796442945408 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I0508 18:55:51.665063 139796442945408 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I0508 18:55:51.665252 139796442945408 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I0508 18:55:51.890037 139796442945408 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I0508 18:55:51.890226 139796442945408 efficientnet_model.py:144] round_filter input=40 output=40\n",
            "I0508 18:55:52.103778 139796442945408 efficientnet_model.py:144] round_filter input=40 output=40\n",
            "I0508 18:55:52.104001 139796442945408 efficientnet_model.py:144] round_filter input=80 output=80\n",
            "I0508 18:55:52.405833 139796442945408 efficientnet_model.py:144] round_filter input=80 output=80\n",
            "I0508 18:55:52.406076 139796442945408 efficientnet_model.py:144] round_filter input=112 output=112\n",
            "I0508 18:55:52.700950 139796442945408 efficientnet_model.py:144] round_filter input=112 output=112\n",
            "I0508 18:55:52.701135 139796442945408 efficientnet_model.py:144] round_filter input=192 output=192\n",
            "I0508 18:55:53.079157 139796442945408 efficientnet_model.py:144] round_filter input=192 output=192\n",
            "I0508 18:55:53.079352 139796442945408 efficientnet_model.py:144] round_filter input=320 output=320\n",
            "I0508 18:55:53.229612 139796442945408 efficientnet_model.py:144] round_filter input=1280 output=1280\n",
            "I0508 18:55:53.259231 139796442945408 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0508 18:55:53.318206 139796442945408 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0508 18:55:53.318384 139796442945408 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n",
            "I0508 18:55:53.318460 139796442945408 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 5\n",
            "I0508 18:55:53.320178 139796442945408 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I0508 18:55:53.335096 139796442945408 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I0508 18:55:53.335229 139796442945408 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I0508 18:55:53.459280 139796442945408 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I0508 18:55:53.459469 139796442945408 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I0508 18:55:53.682727 139796442945408 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I0508 18:55:53.682901 139796442945408 efficientnet_model.py:144] round_filter input=40 output=48\n",
            "I0508 18:55:53.903783 139796442945408 efficientnet_model.py:144] round_filter input=40 output=48\n",
            "I0508 18:55:53.903977 139796442945408 efficientnet_model.py:144] round_filter input=80 output=88\n",
            "I0508 18:55:54.202308 139796442945408 efficientnet_model.py:144] round_filter input=80 output=88\n",
            "I0508 18:55:54.202477 139796442945408 efficientnet_model.py:144] round_filter input=112 output=120\n",
            "I0508 18:55:54.498382 139796442945408 efficientnet_model.py:144] round_filter input=112 output=120\n",
            "I0508 18:55:54.498549 139796442945408 efficientnet_model.py:144] round_filter input=192 output=208\n",
            "I0508 18:55:54.859635 139796442945408 efficientnet_model.py:144] round_filter input=192 output=208\n",
            "I0508 18:55:54.859822 139796442945408 efficientnet_model.py:144] round_filter input=320 output=352\n",
            "I0508 18:55:55.003949 139796442945408 efficientnet_model.py:144] round_filter input=1280 output=1408\n",
            "I0508 18:55:55.031952 139796442945408 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0508 18:55:55.094101 139796442945408 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0508 18:55:55.094262 139796442945408 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n",
            "I0508 18:55:55.094349 139796442945408 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 6\n",
            "I0508 18:55:55.095844 139796442945408 efficientnet_model.py:144] round_filter input=32 output=40\n",
            "I0508 18:55:55.110767 139796442945408 efficientnet_model.py:144] round_filter input=32 output=40\n",
            "I0508 18:55:55.110924 139796442945408 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I0508 18:55:55.434698 139796442945408 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I0508 18:55:55.434883 139796442945408 efficientnet_model.py:144] round_filter input=24 output=32\n",
            "I0508 18:55:55.663935 139796442945408 efficientnet_model.py:144] round_filter input=24 output=32\n",
            "I0508 18:55:55.664118 139796442945408 efficientnet_model.py:144] round_filter input=40 output=48\n",
            "I0508 18:55:55.887773 139796442945408 efficientnet_model.py:144] round_filter input=40 output=48\n",
            "I0508 18:55:55.887952 139796442945408 efficientnet_model.py:144] round_filter input=80 output=96\n",
            "I0508 18:55:56.250514 139796442945408 efficientnet_model.py:144] round_filter input=80 output=96\n",
            "I0508 18:55:56.250702 139796442945408 efficientnet_model.py:144] round_filter input=112 output=136\n",
            "I0508 18:55:56.622341 139796442945408 efficientnet_model.py:144] round_filter input=112 output=136\n",
            "I0508 18:55:56.622520 139796442945408 efficientnet_model.py:144] round_filter input=192 output=232\n",
            "I0508 18:55:57.085076 139796442945408 efficientnet_model.py:144] round_filter input=192 output=232\n",
            "I0508 18:55:57.085277 139796442945408 efficientnet_model.py:144] round_filter input=320 output=384\n",
            "I0508 18:55:57.234977 139796442945408 efficientnet_model.py:144] round_filter input=1280 output=1536\n",
            "I0508 18:55:57.264089 139796442945408 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0508 18:55:57.331045 139796442945408 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0508 18:55:57.331228 139796442945408 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n",
            "I0508 18:55:57.331327 139796442945408 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0508 18:55:57.332958 139796442945408 efficientnet_model.py:144] round_filter input=32 output=48\n",
            "I0508 18:55:57.352192 139796442945408 efficientnet_model.py:144] round_filter input=32 output=48\n",
            "I0508 18:55:57.352358 139796442945408 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I0508 18:55:57.471636 139796442945408 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I0508 18:55:57.471831 139796442945408 efficientnet_model.py:144] round_filter input=24 output=32\n",
            "I0508 18:55:57.775551 139796442945408 efficientnet_model.py:144] round_filter input=24 output=32\n",
            "I0508 18:55:57.775753 139796442945408 efficientnet_model.py:144] round_filter input=40 output=56\n",
            "I0508 18:55:58.069809 139796442945408 efficientnet_model.py:144] round_filter input=40 output=56\n",
            "I0508 18:55:58.070003 139796442945408 efficientnet_model.py:144] round_filter input=80 output=112\n",
            "I0508 18:55:58.513024 139796442945408 efficientnet_model.py:144] round_filter input=80 output=112\n",
            "I0508 18:55:58.513202 139796442945408 efficientnet_model.py:144] round_filter input=112 output=160\n",
            "I0508 18:55:58.952967 139796442945408 efficientnet_model.py:144] round_filter input=112 output=160\n",
            "I0508 18:55:58.953161 139796442945408 efficientnet_model.py:144] round_filter input=192 output=272\n",
            "I0508 18:55:59.543007 139796442945408 efficientnet_model.py:144] round_filter input=192 output=272\n",
            "I0508 18:55:59.543211 139796442945408 efficientnet_model.py:144] round_filter input=320 output=448\n",
            "I0508 18:55:59.692813 139796442945408 efficientnet_model.py:144] round_filter input=1280 output=1792\n",
            "I0508 18:55:59.721066 139796442945408 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0508 18:56:00.003114 139796442945408 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0508 18:56:00.003311 139796442945408 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n",
            "I0508 18:56:00.003398 139796442945408 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0508 18:56:00.005015 139796442945408 efficientnet_model.py:144] round_filter input=32 output=48\n",
            "I0508 18:56:00.020335 139796442945408 efficientnet_model.py:144] round_filter input=32 output=48\n",
            "I0508 18:56:00.020500 139796442945408 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I0508 18:56:00.199638 139796442945408 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I0508 18:56:00.199825 139796442945408 efficientnet_model.py:144] round_filter input=24 output=40\n",
            "I0508 18:56:00.579099 139796442945408 efficientnet_model.py:144] round_filter input=24 output=40\n",
            "I0508 18:56:00.579281 139796442945408 efficientnet_model.py:144] round_filter input=40 output=64\n",
            "I0508 18:56:00.948915 139796442945408 efficientnet_model.py:144] round_filter input=40 output=64\n",
            "I0508 18:56:00.949100 139796442945408 efficientnet_model.py:144] round_filter input=80 output=128\n",
            "I0508 18:56:01.459943 139796442945408 efficientnet_model.py:144] round_filter input=80 output=128\n",
            "I0508 18:56:01.460132 139796442945408 efficientnet_model.py:144] round_filter input=112 output=176\n",
            "I0508 18:56:01.980736 139796442945408 efficientnet_model.py:144] round_filter input=112 output=176\n",
            "I0508 18:56:01.980933 139796442945408 efficientnet_model.py:144] round_filter input=192 output=304\n",
            "I0508 18:56:02.661425 139796442945408 efficientnet_model.py:144] round_filter input=192 output=304\n",
            "I0508 18:56:02.661616 139796442945408 efficientnet_model.py:144] round_filter input=320 output=512\n",
            "I0508 18:56:02.890672 139796442945408 efficientnet_model.py:144] round_filter input=1280 output=2048\n",
            "I0508 18:56:02.921106 139796442945408 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0508 18:56:03.006338 139796442945408 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0508 18:56:03.006493 139796442945408 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0508 18:56:03.006568 139796442945408 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0508 18:56:03.008040 139796442945408 efficientnet_model.py:144] round_filter input=32 output=56\n",
            "I0508 18:56:03.023250 139796442945408 efficientnet_model.py:144] round_filter input=32 output=56\n",
            "I0508 18:56:03.023370 139796442945408 efficientnet_model.py:144] round_filter input=16 output=32\n",
            "I0508 18:56:03.193828 139796442945408 efficientnet_model.py:144] round_filter input=16 output=32\n",
            "I0508 18:56:03.194022 139796442945408 efficientnet_model.py:144] round_filter input=24 output=40\n",
            "I0508 18:56:03.656205 139796442945408 efficientnet_model.py:144] round_filter input=24 output=40\n",
            "I0508 18:56:03.656411 139796442945408 efficientnet_model.py:144] round_filter input=40 output=72\n",
            "I0508 18:56:04.101671 139796442945408 efficientnet_model.py:144] round_filter input=40 output=72\n",
            "I0508 18:56:04.101871 139796442945408 efficientnet_model.py:144] round_filter input=80 output=144\n",
            "I0508 18:56:04.692155 139796442945408 efficientnet_model.py:144] round_filter input=80 output=144\n",
            "I0508 18:56:04.692342 139796442945408 efficientnet_model.py:144] round_filter input=112 output=200\n",
            "I0508 18:56:05.589439 139796442945408 efficientnet_model.py:144] round_filter input=112 output=200\n",
            "I0508 18:56:05.589622 139796442945408 efficientnet_model.py:144] round_filter input=192 output=344\n",
            "I0508 18:56:06.412951 139796442945408 efficientnet_model.py:144] round_filter input=192 output=344\n",
            "I0508 18:56:06.413141 139796442945408 efficientnet_model.py:144] round_filter input=320 output=576\n",
            "I0508 18:56:06.634686 139796442945408 efficientnet_model.py:144] round_filter input=1280 output=2304\n",
            "I0508 18:56:06.666129 139796442945408 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0508 18:56:06.765141 139796442945408 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0508 18:56:06.765331 139796442945408 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0508 18:56:06.765411 139796442945408 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0508 18:56:06.766928 139796442945408 efficientnet_model.py:144] round_filter input=32 output=64\n",
            "I0508 18:56:06.782544 139796442945408 efficientnet_model.py:144] round_filter input=32 output=64\n",
            "I0508 18:56:06.782686 139796442945408 efficientnet_model.py:144] round_filter input=16 output=32\n",
            "I0508 18:56:07.023891 139796442945408 efficientnet_model.py:144] round_filter input=16 output=32\n",
            "I0508 18:56:07.024062 139796442945408 efficientnet_model.py:144] round_filter input=24 output=48\n",
            "I0508 18:56:07.544963 139796442945408 efficientnet_model.py:144] round_filter input=24 output=48\n",
            "I0508 18:56:07.545146 139796442945408 efficientnet_model.py:144] round_filter input=40 output=80\n",
            "I0508 18:56:08.063319 139796442945408 efficientnet_model.py:144] round_filter input=40 output=80\n",
            "I0508 18:56:08.063486 139796442945408 efficientnet_model.py:144] round_filter input=80 output=160\n",
            "I0508 18:56:08.809371 139796442945408 efficientnet_model.py:144] round_filter input=80 output=160\n",
            "I0508 18:56:08.809549 139796442945408 efficientnet_model.py:144] round_filter input=112 output=224\n",
            "I0508 18:56:09.539667 139796442945408 efficientnet_model.py:144] round_filter input=112 output=224\n",
            "I0508 18:56:09.539845 139796442945408 efficientnet_model.py:144] round_filter input=192 output=384\n",
            "I0508 18:56:10.478913 139796442945408 efficientnet_model.py:144] round_filter input=192 output=384\n",
            "I0508 18:56:10.479080 139796442945408 efficientnet_model.py:144] round_filter input=320 output=640\n",
            "I0508 18:56:11.037406 139796442945408 efficientnet_model.py:144] round_filter input=1280 output=2560\n",
            "I0508 18:56:11.064809 139796442945408 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 22.74s\n",
            "I0508 18:56:11.184155 139796442945408 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 22.74s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0508 18:56:11.191042 139796442945408 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0508 18:56:11.192728 139796442945408 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0508 18:56:11.193211 139796442945408 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0508 18:56:11.194687 139796442945408 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0508 18:56:11.195941 139796442945408 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0508 18:56:11.196357 139796442945408 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0508 18:56:11.197392 139796442945408 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 33.967s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ],
      "source": [
        "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
        "# Verify Installation\n",
        "!python {VERIFICATION_SCRIPT}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sN_k0XR_BEPH",
        "outputId": "e4dfbef5-ed66-4b00-aedf-9a49d4f53e33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.4.1\n",
            "  Downloading tensorflow-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 394.3 MB 15 kB/s \n",
            "\u001b[?25hCollecting tensorflow-gpu==2.4.1\n",
            "  Downloading tensorflow_gpu-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 394.3 MB 14 kB/s \n",
            "\u001b[?25hCollecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Collecting tensorflow-estimator<2.5.0,>=2.4.0\n",
            "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 68.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.3.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.1.0)\n",
            "Collecting h5py~=2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 51.1 MB/s \n",
            "\u001b[?25hCollecting numpy~=1.19.2\n",
            "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 45.6 MB/s \n",
            "\u001b[?25hCollecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.2.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (2.8.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.37.1)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.1.2)\n",
            "Collecting absl-py~=0.10\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 71.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.15.0)\n",
            "Collecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting grpcio~=1.32.0\n",
            "  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 57.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.20.1)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.6.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.27.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.8.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.4.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2.0.12)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (3.2.0)\n",
            "Building wheels for collected packages: wrapt\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68722 sha256=c6c351bc81cd87f48df10f57c13b6cc70b4d71a472053c2d1a5b7ba4fd1c5641\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
            "Successfully built wrapt\n",
            "Installing collected packages: typing-extensions, numpy, grpcio, absl-py, wrapt, tensorflow-estimator, h5py, gast, flatbuffers, tensorflow-gpu, tensorflow\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.2.0\n",
            "    Uninstalling typing-extensions-4.2.0:\n",
            "      Successfully uninstalled typing-extensions-4.2.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.44.0\n",
            "    Uninstalling grpcio-1.44.0:\n",
            "      Successfully uninstalled grpcio-1.44.0\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.0.0\n",
            "    Uninstalling absl-py-1.0.0:\n",
            "      Successfully uninstalled absl-py-1.0.0\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.0\n",
            "    Uninstalling wrapt-1.14.0:\n",
            "      Successfully uninstalled wrapt-1.14.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0\n",
            "    Uninstalling tensorflow-2.8.0:\n",
            "      Successfully uninstalled tensorflow-2.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-models-official 2.8.0 requires tensorflow~=2.8.0, but you have tensorflow 2.4.1 which is incompatible.\n",
            "tensorflow-text 2.8.2 requires tensorflow<2.9,>=2.8.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.4.1 which is incompatible.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed absl-py-0.15.0 flatbuffers-1.12 gast-0.3.3 grpcio-1.32.0 h5py-2.10.0 numpy-1.19.5 tensorflow-2.4.1 tensorflow-estimator-2.4.0 tensorflow-gpu-2.4.1 typing-extensions-3.7.4.3 wrapt-1.12.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install tensorflow==2.4.1 tensorflow-gpu==2.4.1 --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "Utv8QOO6BEPH",
        "outputId": "469d10e8-93da-4c16-b244-8167538ef68a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: protobuf 3.20.1\n",
            "Uninstalling protobuf-3.20.1:\n",
            "  Successfully uninstalled protobuf-3.20.1\n",
            "Found existing installation: matplotlib 3.2.2\n",
            "Uninstalling matplotlib-3.2.2:\n",
            "  Successfully uninstalled matplotlib-3.2.2\n",
            "Collecting protobuf\n",
            "  Using cached protobuf-3.20.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "Collecting matplotlib==3.2\n",
            "  Downloading matplotlib-3.2.0-cp37-cp37m-manylinux1_x86_64.whl (12.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.4 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2) (1.19.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2) (1.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2) (3.0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib==3.2) (3.7.4.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib==3.2) (1.15.0)\n",
            "Installing collected packages: protobuf, matplotlib\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-models-official 2.8.0 requires tensorflow~=2.8.0, but you have tensorflow 2.4.1 which is incompatible.\n",
            "tensorflow-text 2.8.2 requires tensorflow<2.9,>=2.8.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.4.1 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed matplotlib-3.2.0 protobuf-3.20.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip uninstall protobuf matplotlib -y\n",
        "!pip install protobuf matplotlib==3.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSZVOZOCBEPH",
        "outputId": "059a6597-aa4b-4a30-b4b7-980b7e72f98e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install Pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Zj8uzrZBEPI",
        "outputId": "415fe39a-d424-4754-e6ff-c208a3cef236"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (5.4.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyyaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NzQiLJvBEPI",
        "outputId": "f3c7e862-86ef-4b9c-a053-12bd049814d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                       Version\n",
            "----------------------------- ---------------------\n",
            "absl-py                       0.15.0\n",
            "alabaster                     0.7.12\n",
            "albumentations                0.1.12\n",
            "altair                        4.2.0\n",
            "apache-beam                   2.38.0\n",
            "appdirs                       1.4.4\n",
            "argon2-cffi                   21.3.0\n",
            "argon2-cffi-bindings          21.2.0\n",
            "arviz                         0.12.0\n",
            "astor                         0.8.1\n",
            "astropy                       4.3.1\n",
            "astunparse                    1.6.3\n",
            "atari-py                      0.2.9\n",
            "atomicwrites                  1.4.0\n",
            "attrs                         21.4.0\n",
            "audioread                     2.1.9\n",
            "autograd                      1.4\n",
            "avro-python3                  1.10.2\n",
            "Babel                         2.10.1\n",
            "backcall                      0.2.0\n",
            "beautifulsoup4                4.6.3\n",
            "bleach                        5.0.0\n",
            "blis                          0.4.1\n",
            "bokeh                         2.3.3\n",
            "Bottleneck                    1.3.4\n",
            "branca                        0.5.0\n",
            "bs4                           0.0.1\n",
            "CacheControl                  0.12.11\n",
            "cached-property               1.5.2\n",
            "cachetools                    4.2.4\n",
            "catalogue                     1.0.0\n",
            "certifi                       2021.10.8\n",
            "cffi                          1.15.0\n",
            "cftime                        1.6.0\n",
            "chardet                       3.0.4\n",
            "charset-normalizer            2.0.12\n",
            "click                         7.1.2\n",
            "cloudpickle                   2.0.0\n",
            "cmake                         3.22.4\n",
            "cmdstanpy                     0.9.5\n",
            "colorama                      0.4.4\n",
            "colorcet                      3.0.0\n",
            "colorlover                    0.3.0\n",
            "community                     1.0.0b1\n",
            "contextlib2                   0.5.5\n",
            "convertdate                   2.4.0\n",
            "coverage                      3.7.1\n",
            "coveralls                     0.5\n",
            "crcmod                        1.7\n",
            "cufflinks                     0.17.3\n",
            "cupy-cuda111                  9.4.0\n",
            "cvxopt                        1.2.7\n",
            "cvxpy                         1.0.31\n",
            "cycler                        0.11.0\n",
            "cymem                         2.0.6\n",
            "Cython                        0.29.28\n",
            "daft                          0.0.4\n",
            "dask                          2.12.0\n",
            "datascience                   0.10.6\n",
            "debugpy                       1.0.0\n",
            "decorator                     4.4.2\n",
            "defusedxml                    0.7.1\n",
            "descartes                     1.1.0\n",
            "dill                          0.3.1.1\n",
            "distributed                   1.25.3\n",
            "dlib                          19.18.0\n",
            "dm-tree                       0.1.7\n",
            "docopt                        0.6.2\n",
            "docutils                      0.17.1\n",
            "dopamine-rl                   1.0.5\n",
            "earthengine-api               0.1.307\n",
            "easydict                      1.9\n",
            "ecos                          2.0.10\n",
            "editdistance                  0.5.3\n",
            "en-core-web-sm                2.2.5\n",
            "entrypoints                   0.4\n",
            "ephem                         4.1.3\n",
            "et-xmlfile                    1.1.0\n",
            "fa2                           0.3.5\n",
            "fastai                        1.0.61\n",
            "fastavro                      1.4.11\n",
            "fastdtw                       0.3.4\n",
            "fastjsonschema                2.15.3\n",
            "fastprogress                  1.0.2\n",
            "fastrlock                     0.8\n",
            "fbprophet                     0.7.1\n",
            "feather-format                0.4.1\n",
            "filelock                      3.6.0\n",
            "firebase-admin                4.4.0\n",
            "fix-yahoo-finance             0.0.22\n",
            "Flask                         1.1.4\n",
            "flatbuffers                   1.12\n",
            "folium                        0.8.3\n",
            "future                        0.16.0\n",
            "gast                          0.3.3\n",
            "GDAL                          2.2.2\n",
            "gdown                         4.4.0\n",
            "gensim                        3.6.0\n",
            "geographiclib                 1.52\n",
            "geopy                         1.17.0\n",
            "gin-config                    0.5.0\n",
            "glob2                         0.7\n",
            "google                        2.0.3\n",
            "google-api-core               1.31.5\n",
            "google-api-python-client      1.12.11\n",
            "google-auth                   1.35.0\n",
            "google-auth-httplib2          0.0.4\n",
            "google-auth-oauthlib          0.4.6\n",
            "google-cloud-bigquery         1.21.0\n",
            "google-cloud-bigquery-storage 1.1.1\n",
            "google-cloud-core             1.0.3\n",
            "google-cloud-datastore        1.8.0\n",
            "google-cloud-firestore        1.7.0\n",
            "google-cloud-language         1.2.0\n",
            "google-cloud-storage          1.18.1\n",
            "google-cloud-translate        1.5.0\n",
            "google-colab                  1.0.0\n",
            "google-pasta                  0.2.0\n",
            "google-resumable-media        0.4.1\n",
            "googleapis-common-protos      1.56.0\n",
            "googledrivedownloader         0.4\n",
            "graphviz                      0.10.1\n",
            "greenlet                      1.1.2\n",
            "grpcio                        1.32.0\n",
            "gspread                       3.4.2\n",
            "gspread-dataframe             3.0.8\n",
            "gym                           0.17.3\n",
            "h5py                          2.10.0\n",
            "hdfs                          2.7.0\n",
            "HeapDict                      1.0.1\n",
            "hijri-converter               2.2.3\n",
            "holidays                      0.10.5.2\n",
            "holoviews                     1.14.8\n",
            "html5lib                      1.0.1\n",
            "httpimport                    0.5.18\n",
            "httplib2                      0.17.4\n",
            "httplib2shim                  0.0.3\n",
            "humanize                      0.5.1\n",
            "hyperopt                      0.1.2\n",
            "ideep4py                      2.0.0.post3\n",
            "idna                          2.10\n",
            "imageio                       2.4.1\n",
            "imagesize                     1.3.0\n",
            "imbalanced-learn              0.8.1\n",
            "imblearn                      0.0\n",
            "imgaug                        0.2.9\n",
            "importlib-metadata            4.11.3\n",
            "importlib-resources           5.7.1\n",
            "imutils                       0.5.4\n",
            "inflect                       2.1.0\n",
            "iniconfig                     1.1.1\n",
            "intel-openmp                  2022.1.0\n",
            "intervaltree                  2.1.0\n",
            "ipykernel                     4.10.1\n",
            "ipython                       5.5.0\n",
            "ipython-genutils              0.2.0\n",
            "ipython-sql                   0.3.9\n",
            "ipywidgets                    7.7.0\n",
            "itsdangerous                  1.1.0\n",
            "jax                           0.3.8\n",
            "jaxlib                        0.3.7+cuda11.cudnn805\n",
            "jedi                          0.18.1\n",
            "jieba                         0.42.1\n",
            "Jinja2                        2.11.3\n",
            "joblib                        1.1.0\n",
            "jpeg4py                       0.1.4\n",
            "jsonschema                    4.3.3\n",
            "jupyter                       1.0.0\n",
            "jupyter-client                5.3.5\n",
            "jupyter-console               5.2.0\n",
            "jupyter-core                  4.10.0\n",
            "jupyterlab-pygments           0.2.2\n",
            "jupyterlab-widgets            1.1.0\n",
            "kaggle                        1.5.12\n",
            "kapre                         0.3.7\n",
            "keras                         2.8.0\n",
            "Keras-Preprocessing           1.1.2\n",
            "keras-vis                     0.4.1\n",
            "kiwisolver                    1.4.2\n",
            "korean-lunar-calendar         0.2.1\n",
            "libclang                      14.0.1\n",
            "librosa                       0.8.1\n",
            "lightgbm                      2.2.3\n",
            "llvmlite                      0.34.0\n",
            "lmdb                          0.99\n",
            "LunarCalendar                 0.0.9\n",
            "lvis                          0.5.3\n",
            "lxml                          4.2.6\n",
            "Markdown                      3.3.6\n",
            "MarkupSafe                    2.0.1\n",
            "matplotlib                    3.2.0\n",
            "matplotlib-inline             0.1.3\n",
            "matplotlib-venn               0.11.7\n",
            "missingno                     0.5.1\n",
            "mistune                       0.8.4\n",
            "mizani                        0.6.0\n",
            "mkl                           2019.0\n",
            "mlxtend                       0.14.0\n",
            "more-itertools                8.12.0\n",
            "moviepy                       0.2.3.5\n",
            "mpmath                        1.2.1\n",
            "msgpack                       1.0.3\n",
            "multiprocess                  0.70.12.2\n",
            "multitasking                  0.0.10\n",
            "murmurhash                    1.0.7\n",
            "music21                       5.5.0\n",
            "natsort                       5.5.0\n",
            "nbclient                      0.6.2\n",
            "nbconvert                     5.6.1\n",
            "nbformat                      5.3.0\n",
            "nest-asyncio                  1.5.5\n",
            "netCDF4                       1.5.8\n",
            "networkx                      2.6.3\n",
            "nibabel                       3.0.2\n",
            "nltk                          3.2.5\n",
            "notebook                      5.3.1\n",
            "numba                         0.51.2\n",
            "numexpr                       2.8.1\n",
            "numpy                         1.19.5\n",
            "nvidia-ml-py3                 7.352.0\n",
            "oauth2client                  4.1.3\n",
            "oauthlib                      3.2.0\n",
            "object-detection              0.1\n",
            "okgrade                       0.4.3\n",
            "opencv-contrib-python         4.1.2.30\n",
            "opencv-python                 4.1.2.30\n",
            "opencv-python-headless        4.5.5.64\n",
            "openpyxl                      3.0.9\n",
            "opt-einsum                    3.3.0\n",
            "orjson                        3.6.8\n",
            "osqp                          0.6.2.post0\n",
            "packaging                     21.3\n",
            "palettable                    3.3.0\n",
            "pandas                        1.3.5\n",
            "pandas-datareader             0.9.0\n",
            "pandas-gbq                    0.13.3\n",
            "pandas-profiling              1.4.1\n",
            "pandocfilters                 1.5.0\n",
            "panel                         0.12.1\n",
            "param                         1.12.1\n",
            "parso                         0.8.3\n",
            "pathlib                       1.0.1\n",
            "patsy                         0.5.2\n",
            "pep517                        0.12.0\n",
            "pexpect                       4.8.0\n",
            "pickleshare                   0.7.5\n",
            "Pillow                        7.1.2\n",
            "pip                           21.1.3\n",
            "pip-tools                     6.2.0\n",
            "plac                          1.1.3\n",
            "plotly                        5.5.0\n",
            "plotnine                      0.6.0\n",
            "pluggy                        0.7.1\n",
            "pooch                         1.6.0\n",
            "portalocker                   2.4.0\n",
            "portpicker                    1.3.9\n",
            "prefetch-generator            1.0.1\n",
            "preshed                       3.0.6\n",
            "prettytable                   3.2.0\n",
            "progressbar2                  3.38.0\n",
            "prometheus-client             0.14.1\n",
            "promise                       2.3\n",
            "prompt-toolkit                1.0.18\n",
            "proto-plus                    1.20.3\n",
            "protobuf                      3.20.1\n",
            "psutil                        5.4.8\n",
            "psycopg2                      2.7.6.1\n",
            "ptyprocess                    0.7.0\n",
            "py                            1.11.0\n",
            "py-cpuinfo                    8.0.0\n",
            "pyarrow                       6.0.1\n",
            "pyasn1                        0.4.8\n",
            "pyasn1-modules                0.2.8\n",
            "pycocotools                   2.0.4\n",
            "pycparser                     2.21\n",
            "pyct                          0.4.8\n",
            "pydata-google-auth            1.4.0\n",
            "pydot                         1.3.0\n",
            "pydot-ng                      2.0.0\n",
            "pydotplus                     2.0.2\n",
            "PyDrive                       1.3.1\n",
            "pyemd                         0.5.1\n",
            "pyerfa                        2.0.0.1\n",
            "pyglet                        1.5.0\n",
            "Pygments                      2.6.1\n",
            "pygobject                     3.26.1\n",
            "pymc3                         3.11.4\n",
            "PyMeeus                       0.5.11\n",
            "pymongo                       3.12.3\n",
            "pymystem3                     0.2.0\n",
            "PyOpenGL                      3.1.6\n",
            "pyparsing                     3.0.8\n",
            "pyrsistent                    0.18.1\n",
            "pysndfile                     1.3.8\n",
            "PySocks                       1.7.1\n",
            "pystan                        2.19.1.1\n",
            "pytest                        3.6.4\n",
            "python-apt                    0.0.0\n",
            "python-chess                  0.23.11\n",
            "python-dateutil               2.8.2\n",
            "python-louvain                0.16\n",
            "python-slugify                6.1.2\n",
            "python-utils                  3.1.0\n",
            "pytz                          2022.1\n",
            "pyviz-comms                   2.2.0\n",
            "PyWavelets                    1.3.0\n",
            "PyYAML                        5.4.1\n",
            "pyzmq                         22.3.0\n",
            "qdldl                         0.1.5.post2\n",
            "qtconsole                     5.3.0\n",
            "QtPy                          2.1.0\n",
            "regex                         2019.12.20\n",
            "requests                      2.27.1\n",
            "requests-oauthlib             1.3.1\n",
            "resampy                       0.2.2\n",
            "rpy2                          3.4.5\n",
            "rsa                           4.8\n",
            "sacrebleu                     2.0.0\n",
            "scikit-image                  0.18.3\n",
            "scikit-learn                  1.0.2\n",
            "scipy                         1.4.1\n",
            "screen-resolution-extra       0.0.0\n",
            "scs                           3.2.0\n",
            "seaborn                       0.11.2\n",
            "semver                        2.13.0\n",
            "Send2Trash                    1.8.0\n",
            "sentencepiece                 0.1.96\n",
            "seqeval                       1.2.2\n",
            "setuptools                    57.4.0\n",
            "setuptools-git                1.2\n",
            "Shapely                       1.8.1.post1\n",
            "simplegeneric                 0.8.1\n",
            "six                           1.15.0\n",
            "sklearn                       0.0\n",
            "sklearn-pandas                1.8.0\n",
            "smart-open                    6.0.0\n",
            "snowballstemmer               2.2.0\n",
            "sortedcontainers              2.4.0\n",
            "SoundFile                     0.10.3.post1\n",
            "soupsieve                     2.3.2.post1\n",
            "spacy                         2.2.4\n",
            "Sphinx                        1.8.6\n",
            "sphinxcontrib-serializinghtml 1.1.5\n",
            "sphinxcontrib-websupport      1.2.4\n",
            "SQLAlchemy                    1.4.36\n",
            "sqlparse                      0.4.2\n",
            "srsly                         1.0.5\n",
            "statsmodels                   0.10.2\n",
            "sympy                         1.7.1\n",
            "tables                        3.7.0\n",
            "tabulate                      0.8.9\n",
            "tblib                         1.7.0\n",
            "tenacity                      8.0.1\n",
            "tensorboard                   2.8.0\n",
            "tensorboard-data-server       0.6.1\n",
            "tensorboard-plugin-wit        1.8.1\n",
            "tensorflow                    2.4.1\n",
            "tensorflow-addons             0.16.1\n",
            "tensorflow-datasets           4.0.1\n",
            "tensorflow-estimator          2.4.0\n",
            "tensorflow-gcs-config         2.8.0\n",
            "tensorflow-gpu                2.4.1\n",
            "tensorflow-hub                0.12.0\n",
            "tensorflow-io                 0.25.0\n",
            "tensorflow-io-gcs-filesystem  0.25.0\n",
            "tensorflow-metadata           1.7.0\n",
            "tensorflow-model-optimization 0.7.2\n",
            "tensorflow-probability        0.16.0\n",
            "tensorflow-text               2.8.2\n",
            "termcolor                     1.1.0\n",
            "terminado                     0.13.3\n",
            "testpath                      0.6.0\n",
            "text-unidecode                1.3\n",
            "textblob                      0.15.3\n",
            "tf-estimator-nightly          2.8.0.dev2021122109\n",
            "tf-models-official            2.8.0\n",
            "tf-slim                       1.1.0\n",
            "Theano-PyMC                   1.1.2\n",
            "thinc                         7.4.0\n",
            "threadpoolctl                 3.1.0\n",
            "tifffile                      2021.11.2\n",
            "tinycss2                      1.1.1\n",
            "tomli                         2.0.1\n",
            "toolz                         0.11.2\n",
            "torch                         1.11.0+cu113\n",
            "torchaudio                    0.11.0+cu113\n",
            "torchsummary                  1.5.1\n",
            "torchtext                     0.12.0\n",
            "torchvision                   0.12.0+cu113\n",
            "tornado                       5.1.1\n",
            "tqdm                          4.64.0\n",
            "traitlets                     5.1.1\n",
            "tweepy                        3.10.0\n",
            "typeguard                     2.7.1\n",
            "typing-extensions             3.7.4.3\n",
            "tzlocal                       1.5.1\n",
            "uritemplate                   3.0.1\n",
            "urllib3                       1.24.3\n",
            "vega-datasets                 0.9.0\n",
            "wasabi                        0.9.1\n",
            "wcwidth                       0.2.5\n",
            "webencodings                  0.5.1\n",
            "Werkzeug                      1.0.1\n",
            "wheel                         0.37.1\n",
            "widgetsnbextension            3.6.0\n",
            "wordcloud                     1.5.0\n",
            "wrapt                         1.12.1\n",
            "xarray                        0.18.2\n",
            "xgboost                       0.90\n",
            "xkit                          0.0.0\n",
            "xlrd                          1.1.0\n",
            "xlwt                          1.3.0\n",
            "yellowbrick                   1.4\n",
            "zict                          2.2.0\n",
            "zipp                          3.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "pe-QtgS0BEPI"
      },
      "outputs": [],
      "source": [
        "import object_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csofht2npfDE",
        "outputId": "19d46cc4-fc69-414c-f61c-0ed6f15ca1da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-08 18:58:14--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.20.128, 2607:f8b0:400e:c08::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.20.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20515344 (20M) [application/x-tar]\n",
            "Saving to: ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’\n",
            "\n",
            "ssd_mobilenet_v2_fp 100%[===================>]  19.56M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2022-05-08 18:58:14 (271 MB/s) - ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’ saved [20515344/20515344]\n",
            "\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"
          ]
        }
      ],
      "source": [
        "if os.name =='posix':\n",
        "    !wget {PRETRAINED_MODEL_URL}\n",
        "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
        "if os.name == 'nt':\n",
        "    wget.download(PRETRAINED_MODEL_URL)\n",
        "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5KJTnkfpfDC"
      },
      "source": [
        "# 2. Create Label Map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "p1BVDWo7pfDC"
      },
      "outputs": [],
      "source": [
        "labels = [{'name':'licence', 'id':1}]\n",
        "\n",
        "with open(files['LABELMAP'], 'w') as f:\n",
        "    for label in labels:\n",
        "        f.write('item { \\n')\n",
        "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "        f.write('\\tid:{}\\n'.format(label['id']))\n",
        "        f.write('}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C88zyVELpfDC"
      },
      "source": [
        "# 3. Create TF records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "kvf5WccwrFGq"
      },
      "outputs": [],
      "source": [
        "# OPTIONAL IF RUNNING ON COLAB\n",
        "ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n",
        "if os.path.exists(ARCHIVE_FILES):\n",
        "  !tar -zxvf {ARCHIVE_FILES}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWpb_BVUpfDD",
        "outputId": "a4fc0e3a-0ce1-49ec-ee19-20689c60cf15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Tensorflow/scripts'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 1 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (3/3), done.\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
        "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgJiQkikBEPK",
        "outputId": "5435d767-afc1-4a4a-eddc-44448b6b93ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (2022.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pytz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPFToGZqpfDD",
        "outputId": "5c3eac9c-75f9-4201-9616-ae068f70257d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created the TFRecord file: Tensorflow/workspace/annotations/train.record\n",
            "Successfully created the TFRecord file: Tensorflow/workspace/annotations/test.record\n"
          ]
        }
      ],
      "source": [
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qT4QU7pLpfDE"
      },
      "source": [
        "# 4. Copy Model Config to Training Folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "cOjuTFbwpfDF"
      },
      "outputs": [],
      "source": [
        "if os.name =='posix':\n",
        "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
        "if os.name == 'nt':\n",
        "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga8gpNslpfDF"
      },
      "source": [
        "# 5. Update Config For Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Z9hRrO_ppfDF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "c2A0mn4ipfDF"
      },
      "outputs": [],
      "source": [
        "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQA13-afpfDF",
        "outputId": "dceb3b34-9c01-4ce8-b9e0-72206ac273a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_config': metrics_set: \"coco_detection_metrics\"\n",
              " use_moving_averages: false,\n",
              " 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " },\n",
              " 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }\n",
              " ],\n",
              " 'model': ssd {\n",
              "   num_classes: 90\n",
              "   image_resizer {\n",
              "     fixed_shape_resizer {\n",
              "       height: 320\n",
              "       width: 320\n",
              "     }\n",
              "   }\n",
              "   feature_extractor {\n",
              "     type: \"ssd_mobilenet_v2_fpn_keras\"\n",
              "     depth_multiplier: 1.0\n",
              "     min_depth: 16\n",
              "     conv_hyperparams {\n",
              "       regularizer {\n",
              "         l2_regularizer {\n",
              "           weight: 3.9999998989515007e-05\n",
              "         }\n",
              "       }\n",
              "       initializer {\n",
              "         random_normal_initializer {\n",
              "           mean: 0.0\n",
              "           stddev: 0.009999999776482582\n",
              "         }\n",
              "       }\n",
              "       activation: RELU_6\n",
              "       batch_norm {\n",
              "         decay: 0.996999979019165\n",
              "         scale: true\n",
              "         epsilon: 0.0010000000474974513\n",
              "       }\n",
              "     }\n",
              "     use_depthwise: true\n",
              "     override_base_feature_extractor_hyperparams: true\n",
              "     fpn {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       additional_layer_depth: 128\n",
              "     }\n",
              "   }\n",
              "   box_coder {\n",
              "     faster_rcnn_box_coder {\n",
              "       y_scale: 10.0\n",
              "       x_scale: 10.0\n",
              "       height_scale: 5.0\n",
              "       width_scale: 5.0\n",
              "     }\n",
              "   }\n",
              "   matcher {\n",
              "     argmax_matcher {\n",
              "       matched_threshold: 0.5\n",
              "       unmatched_threshold: 0.5\n",
              "       ignore_thresholds: false\n",
              "       negatives_lower_than_unmatched: true\n",
              "       force_match_for_each_row: true\n",
              "       use_matmul_gather: true\n",
              "     }\n",
              "   }\n",
              "   similarity_calculator {\n",
              "     iou_similarity {\n",
              "     }\n",
              "   }\n",
              "   box_predictor {\n",
              "     weight_shared_convolutional_box_predictor {\n",
              "       conv_hyperparams {\n",
              "         regularizer {\n",
              "           l2_regularizer {\n",
              "             weight: 3.9999998989515007e-05\n",
              "           }\n",
              "         }\n",
              "         initializer {\n",
              "           random_normal_initializer {\n",
              "             mean: 0.0\n",
              "             stddev: 0.009999999776482582\n",
              "           }\n",
              "         }\n",
              "         activation: RELU_6\n",
              "         batch_norm {\n",
              "           decay: 0.996999979019165\n",
              "           scale: true\n",
              "           epsilon: 0.0010000000474974513\n",
              "         }\n",
              "       }\n",
              "       depth: 128\n",
              "       num_layers_before_predictor: 4\n",
              "       kernel_size: 3\n",
              "       class_prediction_bias_init: -4.599999904632568\n",
              "       share_prediction_tower: true\n",
              "       use_depthwise: true\n",
              "     }\n",
              "   }\n",
              "   anchor_generator {\n",
              "     multiscale_anchor_generator {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       anchor_scale: 4.0\n",
              "       aspect_ratios: 1.0\n",
              "       aspect_ratios: 2.0\n",
              "       aspect_ratios: 0.5\n",
              "       scales_per_octave: 2\n",
              "     }\n",
              "   }\n",
              "   post_processing {\n",
              "     batch_non_max_suppression {\n",
              "       score_threshold: 9.99999993922529e-09\n",
              "       iou_threshold: 0.6000000238418579\n",
              "       max_detections_per_class: 100\n",
              "       max_total_detections: 100\n",
              "       use_static_shapes: false\n",
              "     }\n",
              "     score_converter: SIGMOID\n",
              "   }\n",
              "   normalize_loss_by_num_matches: true\n",
              "   loss {\n",
              "     localization_loss {\n",
              "       weighted_smooth_l1 {\n",
              "       }\n",
              "     }\n",
              "     classification_loss {\n",
              "       weighted_sigmoid_focal {\n",
              "         gamma: 2.0\n",
              "         alpha: 0.25\n",
              "       }\n",
              "     }\n",
              "     classification_weight: 1.0\n",
              "     localization_weight: 1.0\n",
              "   }\n",
              "   encode_background_as_zeros: true\n",
              "   normalize_loc_loss_by_codesize: true\n",
              "   inplace_batchnorm_update: true\n",
              "   freeze_batchnorm: false\n",
              " },\n",
              " 'train_config': batch_size: 128\n",
              " data_augmentation_options {\n",
              "   random_horizontal_flip {\n",
              "   }\n",
              " }\n",
              " data_augmentation_options {\n",
              "   random_crop_image {\n",
              "     min_object_covered: 0.0\n",
              "     min_aspect_ratio: 0.75\n",
              "     max_aspect_ratio: 3.0\n",
              "     min_area: 0.75\n",
              "     max_area: 1.0\n",
              "     overlap_thresh: 0.0\n",
              "   }\n",
              " }\n",
              " sync_replicas: true\n",
              " optimizer {\n",
              "   momentum_optimizer {\n",
              "     learning_rate {\n",
              "       cosine_decay_learning_rate {\n",
              "         learning_rate_base: 0.07999999821186066\n",
              "         total_steps: 50000\n",
              "         warmup_learning_rate: 0.026666000485420227\n",
              "         warmup_steps: 1000\n",
              "       }\n",
              "     }\n",
              "     momentum_optimizer_value: 0.8999999761581421\n",
              "   }\n",
              "   use_moving_average: false\n",
              " }\n",
              " fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
              " num_steps: 50000\n",
              " startup_delay_steps: 0.0\n",
              " replicas_to_aggregate: 8\n",
              " max_number_of_boxes: 100\n",
              " unpad_groundtruth_tensors: false\n",
              " fine_tune_checkpoint_type: \"classification\"\n",
              " fine_tune_checkpoint_version: V2,\n",
              " 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "9vK5lotDpfDF"
      },
      "outputs": [],
      "source": [
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
        "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
        "    text_format.Merge(proto_str, pipeline_config)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "rP43Ph0JpfDG"
      },
      "outputs": [],
      "source": [
        "pipeline_config.model.ssd.num_classes = len(labels)\n",
        "pipeline_config.train_config.batch_size = 4\n",
        "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
        "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "oJvfgwWqpfDG"
      },
      "outputs": [],
      "source": [
        "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
        "    f.write(config_text)   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zr3ON7xMpfDG"
      },
      "source": [
        "# 6. Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "B-Y2UQmQpfDG"
      },
      "outputs": [],
      "source": [
        "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "jMP2XDfQpfDH"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=10000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4OXXi-ApfDH",
        "outputId": "cbf7d887-7b72-4325-e021-fda82a1aa350"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_ssd_mobnet --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --num_train_steps=10000\n"
          ]
        }
      ],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3ZsJR-qpfDH",
        "outputId": "1ea1c47d-96e7-4021-9c0a-4afa9142b54e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-05-08 18:58:26.762798: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "Traceback (most recent call last):\n",
            "  File \"Tensorflow/models/research/object_detection/model_main_tf2.py\", line 31, in <module>\n",
            "    from object_detection import model_lib_v2\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py\", line 29, in <module>\n",
            "    from object_detection import eval_util\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/eval_util.py\", line 35, in <module>\n",
            "    from object_detection.metrics import coco_evaluation\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/metrics/coco_evaluation.py\", line 25, in <module>\n",
            "    from object_detection.metrics import coco_tools\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/metrics/coco_tools.py\", line 51, in <module>\n",
            "    from pycocotools import coco\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pycocotools/coco.py\", line 52, in <module>\n",
            "    from . import mask as maskUtils\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pycocotools/mask.py\", line 3, in <module>\n",
            "    import pycocotools._mask as _mask\n",
            "  File \"pycocotools/_mask.pyx\", line 1, in init pycocotools._mask\n",
            "ValueError: numpy.ndarray size changed, may indicate binary incompatibility. Expected 88 from C header, got 80 from PyObject\n"
          ]
        }
      ],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_YRZu7npfDH"
      },
      "source": [
        "# 7. Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "80L7-fdPpfDH"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYsgEPx9pfDH",
        "outputId": "15bfe594-1b96-431c-cc65-8c8638a5e8b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_ssd_mobnet --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --checkpoint_dir=Tensorflow/workspace/models/my_ssd_mobnet\n"
          ]
        }
      ],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "lqTV2jGBpfDH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a14d5b1a-ea62-4e0c-df8a-4525d95e444f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-05-08 18:58:29.216034: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "Traceback (most recent call last):\n",
            "  File \"Tensorflow/models/research/object_detection/model_main_tf2.py\", line 31, in <module>\n",
            "    from object_detection import model_lib_v2\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py\", line 29, in <module>\n",
            "    from object_detection import eval_util\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/eval_util.py\", line 35, in <module>\n",
            "    from object_detection.metrics import coco_evaluation\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/metrics/coco_evaluation.py\", line 25, in <module>\n",
            "    from object_detection.metrics import coco_tools\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/metrics/coco_tools.py\", line 51, in <module>\n",
            "    from pycocotools import coco\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pycocotools/coco.py\", line 52, in <module>\n",
            "    from . import mask as maskUtils\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pycocotools/mask.py\", line 3, in <module>\n",
            "    import pycocotools._mask as _mask\n",
            "  File \"pycocotools/_mask.pyx\", line 1, in init pycocotools._mask\n",
            "ValueError: numpy.ndarray size changed, may indicate binary incompatibility. Expected 88 from C header, got 80 from PyObject\n"
          ]
        }
      ],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orvRk02UpfDI"
      },
      "source": [
        "# 8. Load Train Model From Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "8TYk4_oIpfDI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "9308d198-d33d-48e0-acbb-01bd5b305466"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AlreadyExistsError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAlreadyExistsError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-47dd4b277c51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlabel_map_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvisualization_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mviz_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_builder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_architectures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcenter_net_meta_arch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_architectures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext_rcnn_meta_arch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_architectures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeepmac_meta_arch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_architectures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfaster_rcnn_meta_arch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_architectures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrfcn_meta_arch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/object_detection/meta_architectures/deepmac_meta_arch.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtf_version\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tf2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m   \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_io\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfio\u001b[0m  \u001b[0;31m# pylint:disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_io/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\"\"\"tensorflow_io\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# pylint: disable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVERSION\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_io/python/api/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# tensorflow_io.core.python.ops is implicitly imported (along with file system)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIODataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio_tensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIOTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_io/python/ops/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0mcore_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLazyLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"core_ops\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"libtensorflow_io.so\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mplugin_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"libtensorflow_io_plugins.so\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"unable to load libtensorflow_io_plugins.so: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_io/python/ops/__init__.py\u001b[0m in \u001b[0;36m_load_library\u001b[0;34m(filename, lib)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_io/python/ops/__init__.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mload_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRTLD_GLOBAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlib\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"fs\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mload_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_filesystem_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mload_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_file_system_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/load_library.py\u001b[0m in \u001b[0;36mregister_filesystem_plugin\u001b[0;34m(plugin_location)\u001b[0m\n\u001b[1;32m    176\u001b[0m   \"\"\"\n\u001b[1;32m    177\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplugin_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     \u001b[0mpy_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_RegisterFilesystemPlugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplugin_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAlreadyExistsError\u001b[0m: File system for s3 already registered"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "from object_detection.utils import config_util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7HcxnvABEPN"
      },
      "outputs": [],
      "source": [
        "# Prevent GPU complete consumption\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try: \n",
        "        tf.config.experimental.set_virtual_device_configuration(\n",
        "            gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)])\n",
        "    except RunTimeError as e:\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDnQg-cYpfDI"
      },
      "outputs": [],
      "source": [
        "# Load pipeline config and build a detection model\n",
        "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
        "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
        "\n",
        "# Restore checkpoint\n",
        "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-11')).expect_partial()\n",
        "\n",
        "@tf.function\n",
        "def detect_fn(image):\n",
        "    image, shapes = detection_model.preprocess(image)\n",
        "    prediction_dict = detection_model.predict(image, shapes)\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "    return detections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EmsmbBZpfDI"
      },
      "source": [
        "# 9. Detect from an Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_MKiuZ4pfDI"
      },
      "outputs": [],
      "source": [
        "import cv2 \n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBDbIhNapfDI"
      },
      "outputs": [],
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lx3crOhOzITB"
      },
      "outputs": [],
      "source": [
        "IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'testimg2.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tpzn1SMry1yK"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread(IMAGE_PATH)\n",
        "image_np = np.array(img)\n",
        "\n",
        "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "detections = detect_fn(input_tensor)\n",
        "\n",
        "num_detections = int(detections.pop('num_detections'))\n",
        "detections = {key: value[0, :num_detections].numpy()\n",
        "              for key, value in detections.items()}\n",
        "detections['num_detections'] = num_detections\n",
        "\n",
        "# detection_classes should be ints.\n",
        "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "label_id_offset = 1\n",
        "image_np_with_detections = image_np.copy()\n",
        "\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "            image_np_with_detections,\n",
        "            detections['detection_boxes'],\n",
        "            detections['detection_classes']+label_id_offset,\n",
        "            detections['detection_scores'],\n",
        "            category_index,\n",
        "            use_normalized_coordinates=True,\n",
        "            max_boxes_to_draw=5,\n",
        "            min_score_thresh=.8,\n",
        "            agnostic_mode=False)\n",
        "\n",
        "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShlCjBCdBEPO"
      },
      "outputs": [],
      "source": [
        "detections.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "608cbqQsBEPP"
      },
      "source": [
        "# Apply OCR to Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWNVma1-BEPP"
      },
      "outputs": [],
      "source": [
        "!pip install easyocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knbn43uABEPP"
      },
      "outputs": [],
      "source": [
        "!pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio===0.8.1 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzAXRoBHBEPQ"
      },
      "outputs": [],
      "source": [
        "import easyocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZFhYN03BEPQ"
      },
      "outputs": [],
      "source": [
        "detection_threshold = 0.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISb8A_WXBEPQ"
      },
      "outputs": [],
      "source": [
        "image = image_np_with_detections\n",
        "scores = list(filter(lambda x: x> detection_threshold, detections['detection_scores']))\n",
        "boxes = detections['detection_boxes'][:len(scores)]\n",
        "classes = detections['detection_classes'][:len(scores)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COflGWYMBEPQ"
      },
      "outputs": [],
      "source": [
        "width = image.shape[1]\n",
        "height = image.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6xVNy-9BEPR"
      },
      "outputs": [],
      "source": [
        "# Apply ROI filtering and OCR\n",
        "for idx, box in enumerate(boxes):\n",
        "    print(box)\n",
        "    roi = box*[height, width, height, width]\n",
        "    print(roi)\n",
        "    region = image[int(roi[0]):int(roi[2]),int(roi[1]):int(roi[3])]\n",
        "    reader = easyocr.Reader(['en'])\n",
        "    ocr_result = reader.readtext(region)\n",
        "    print(ocr_result)\n",
        "    plt.imshow(cv2.cvtColor(region, cv2.COLOR_BGR2RGB))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3-Qcw8RBEPR"
      },
      "outputs": [],
      "source": [
        "for result in ocr_result:\n",
        "    print(np.sum(np.subtract(result[0][2],result[0][1])))\n",
        "    print(result[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qcrfa--MBEPR"
      },
      "source": [
        "# OCR Filtering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rX23aW7_BEPR"
      },
      "outputs": [],
      "source": [
        "region_threshold = 0.05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLw3OcnxBEPR"
      },
      "outputs": [],
      "source": [
        "def filter_text(region, ocr_result, region_threshold):\n",
        "    rectangle_size = region.shape[0]*region.shape[1]\n",
        "    \n",
        "    plate = [] \n",
        "    for result in ocr_result:\n",
        "        length = np.sum(np.subtract(result[0][1], result[0][0]))\n",
        "        height = np.sum(np.subtract(result[0][2], result[0][1]))\n",
        "        \n",
        "        if length*height / rectangle_size > region_threshold:\n",
        "            plate.append(result[1])\n",
        "    return plate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "is8KvVBzBEPR"
      },
      "outputs": [],
      "source": [
        "filter_text(region, ocr_result, region_threshold)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbq4XLICBEPS"
      },
      "source": [
        "# Bring it Together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITHbe5A9BEPS"
      },
      "outputs": [],
      "source": [
        "region_threshold = 0.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wk57lOIWBEPS"
      },
      "outputs": [],
      "source": [
        "def ocr_it(image, detections, detection_threshold, region_threshold):\n",
        "    \n",
        "    # Scores, boxes and classes above threhold\n",
        "    scores = list(filter(lambda x: x> detection_threshold, detections['detection_scores']))\n",
        "    boxes = detections['detection_boxes'][:len(scores)]\n",
        "    classes = detections['detection_classes'][:len(scores)]\n",
        "    \n",
        "    # Full image dimensions\n",
        "    width = image.shape[1]\n",
        "    height = image.shape[0]\n",
        "    \n",
        "    # Apply ROI filtering and OCR\n",
        "    for idx, box in enumerate(boxes):\n",
        "        roi = box*[height, width, height, width]\n",
        "        region = image[int(roi[0]):int(roi[2]),int(roi[1]):int(roi[3])]\n",
        "        reader = easyocr.Reader(['en'])\n",
        "        ocr_result = reader.readtext(region)\n",
        "        \n",
        "        text = filter_text(region, ocr_result, region_threshold)\n",
        "        \n",
        "        plt.imshow(cv2.cvtColor(region, cv2.COLOR_BGR2RGB))\n",
        "        plt.show()\n",
        "        print(text)\n",
        "        return text, region"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "76xECDsiBEPS"
      },
      "outputs": [],
      "source": [
        "text, region = ocr_it(image_np_with_detections, detections, detection_threshold, region_threshold)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwCOWzRABEPS"
      },
      "source": [
        "# Save Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcMTkdJYBEPS"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import uuid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBl7U2eEBEPS"
      },
      "outputs": [],
      "source": [
        "'{}.jpg'.format(uuid.uuid1())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVVMuv9tBEPT"
      },
      "outputs": [],
      "source": [
        "def save_results(text, region, csv_filename, folder_path):\n",
        "    img_name = '{}.jpg'.format(uuid.uuid1())\n",
        "    \n",
        "    cv2.imwrite(os.path.join(folder_path, img_name), region)\n",
        "    \n",
        "    with open(csv_filename, mode='a', newline='') as f:\n",
        "        csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "        csv_writer.writerow([img_name, text])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCK6nZf9BEPT"
      },
      "outputs": [],
      "source": [
        "region"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsV65GQaBEPT"
      },
      "outputs": [],
      "source": [
        "save_results(text, region, 'detection_results.csv', 'Detection_Images')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsNAaYAo0WVL"
      },
      "source": [
        "# 10. Real Time Detections from your Webcam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4h7vm-pBEPT"
      },
      "outputs": [],
      "source": [
        "!pip uninstall opencv-python-headless -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_grs6OGpfDJ"
      },
      "outputs": [],
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "while cap.isOpened(): \n",
        "    ret, frame = cap.read()\n",
        "    image_np = np.array(frame)\n",
        "    \n",
        "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "    detections = detect_fn(input_tensor)\n",
        "    \n",
        "    num_detections = int(detections.pop('num_detections'))\n",
        "    detections = {key: value[0, :num_detections].numpy()\n",
        "                  for key, value in detections.items()}\n",
        "    detections['num_detections'] = num_detections\n",
        "\n",
        "    # detection_classes should be ints.\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "    label_id_offset = 1\n",
        "    image_np_with_detections = image_np.copy()\n",
        "\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "                image_np_with_detections,\n",
        "                detections['detection_boxes'],\n",
        "                detections['detection_classes']+label_id_offset,\n",
        "                detections['detection_scores'],\n",
        "                category_index,\n",
        "                use_normalized_coordinates=True,\n",
        "                max_boxes_to_draw=5,\n",
        "                min_score_thresh=.8,\n",
        "                agnostic_mode=False)\n",
        "    \n",
        "    try: \n",
        "        text, region = ocr_it(image_np_with_detections, detections, detection_threshold, region_threshold)\n",
        "        save_results(text, region, 'realtimeresults.csv', 'Detection_Images')\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n",
        "    \n",
        "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzlM4jt0pfDJ"
      },
      "source": [
        "# 10. Freezing the Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4olHB2npfDJ"
      },
      "outputs": [],
      "source": [
        "FREEZE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AjO93QDpfDJ"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['OUTPUT_PATH'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6Lsp3tCpfDJ"
      },
      "outputs": [],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Sw1ULgHpfDJ"
      },
      "outputs": [],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTPmdqaXpfDK"
      },
      "source": [
        "# 11. Conversion to TFJS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZ6UzY_fpfDK",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "!pip install tensorflowjs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oxbVynHpfDK"
      },
      "outputs": [],
      "source": [
        "command = \"tensorflowjs_converter --input_format=tf_saved_model --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' --output_format=tfjs_graph_model --signature_name=serving_default {} {}\".format(os.path.join(paths['OUTPUT_PATH'], 'saved_model'), paths['TFJS_PATH'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DB2AGNmJpfDK"
      },
      "outputs": [],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7rfT4-hpfDK"
      },
      "outputs": [],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8_hm-itpfDK"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtUw73FHpfDK"
      },
      "source": [
        "# 12. Conversion to TFLite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XviMtewLpfDK"
      },
      "outputs": [],
      "source": [
        "TFLITE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'export_tflite_graph_tf2.py ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "us86cjC4pfDL"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(TFLITE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['TFLITE_PATH'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1r5YO3rpfDL"
      },
      "outputs": [],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-xWpHN8pfDL"
      },
      "outputs": [],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJfYMbN6pfDL"
      },
      "outputs": [],
      "source": [
        "FROZEN_TFLITE_PATH = os.path.join(paths['TFLITE_PATH'], 'saved_model')\n",
        "TFLITE_MODEL = os.path.join(paths['TFLITE_PATH'], 'saved_model', 'detect.tflite')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDPmV39cBEPW"
      },
      "outputs": [],
      "source": [
        "command = \"tflite_convert \\\n",
        "--saved_model_dir={} \\\n",
        "--output_file={} \\\n",
        "--input_shapes=1,300,300,3 \\\n",
        "--input_arrays=normalized_input_image_tensor \\\n",
        "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
        "--inference_type=FLOAT \\\n",
        "--allow_custom_ops\".format(FROZEN_TFLITE_PATH, TFLITE_MODEL, )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8GwUeoFpfDL"
      },
      "outputs": [],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nbd7gqHMpfDL"
      },
      "outputs": [],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NQqZRdA21Uc"
      },
      "source": [
        "# 13. Zip and Export Models "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTVTGCQp2ZJJ"
      },
      "outputs": [],
      "source": [
        "!tar -czf models.tar.gz {paths['CHECKPOINT_PATH']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whShhB0x3PYJ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ANPR.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "anprsys",
      "language": "python",
      "name": "anprsys"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}